<!DOCTYPE HTML>
<html>
    <head>
     <title>Research</title><link rel="shortcut icon" href="AI.ico"/>
      <meta charset="utf-8">
      <link rel="stylesheet" href="css.css" >
    </head>
    <style>
body {
       background-image: url(Background-website-01.jpg);
       background-repeat: no-repeat;
       background-attachment: fixed;
       background-size: 100% 100%;
}
.header {
 
        padding: 15px;
        text-align: center;
        background:rgba(26,188,156,.83);
        color: white;
        font-size:25px;
        font-family: Arial, Helvetica, sans-serif,"Times New Roman", Times, serif;
}
nav{box-shadow: -1px 6px 1px rgba(26,188,156,.3);
 padding: 10px;
        text-align: center;
        background:rgba(26,188,156,.83);
        color: white;
        font-size:25px;
 font-family: Arial, Helvetica, sans-serif,"Times New Roman", Times, serif;
 position:sticky;
 top:0;
 left:0;
 border-top:0}


a{
        color: white;
        font-size:30px;
        text-decoration: none
}
a:hover{
        color: #f00;
        font-weight: bold;
        font-size:35px
}
a:active{

        color: #080;
        font-weight: normal
}
.header2{
        font-family: Arial, Helvetica, sans-serif,"Times New Roman", Times, serif;
        color: #C70039;
   }

.paragraph{
  font-family: Arial, Helvetica, sans-serif,"Times New Roman", Times, serif;
  font-size: 20px
}

.img{text-align: center}

span.p2{
 font-weight: bold;
 font-size: 1.2em;
 color: #3488DB
}
span.p3{
 font-weight: bold;
 font-size: 1.1em;
 text-decoration: underline;
 color:#797D7F
}
</style>
    <body>
 <div class="header">
  <h1>Artificial Intelligence (AI)</h1>
       
         
           
  </div>
     <nav >
            <table style="width:100%">
 <tr>
    <th><a href="Student.html">Student</a></th>
    <th><a href="Abstract.html">Abstract</a></th>
    <th><a style="text-decoration: underline" href="index.html">Research</a></th> 
    <td><a href="Conclusions.html">Conclusions</a></td>
    <th><a href="References.html">References</a></th>
 <th><a
  </tr>
           </table>
 </nav>
     
     <div class="header2">
      <h1>Introduction:-</h1>
     </div>
    
     <div class="img"> <img src="pics/artificial intelligence.jpg" alt="artificial intelligence">
    </div>
    <div class="paragraph">
    <p>Artificial Intelligence (AI), the ability of a computer-controlled robot or digital computer to perform tasks common to smart beings. The term is often applied to the project of developing systems endowed with intellectual processes characteristic of humans such as the ability to reason, discover meaning, generalize or learn from past experience. Since the digital computer 's development in the 1940s, it has been shown that computers can be programmed to perform very complex tasks – such as discovering proofs for mathematical theorems or playing chess – with great skill Nevertheless, despite continuing advances in computer processing speed and memory capacity, no programs are yet available that can match human flexibility over wider domains or tasks requiring a great deal of daily knowledge. On the other hand, some programs have achieved the performance levels of human experts and professionals in certain specific tasks, so that artificial intelligence can be found in applications as diverse as medical diagnosis, computer search engines, and recognition of voice or handwriting.</p>
   </div>
    
    <div class="header2">
      <h1>Artificial intelligence is evolving all by itself</h1>
     </div>
       
        <div class="img"> <img src="pics/Artificial intelligence is evolving all by itself.jpg" alt="Artificial intelligence is evolving all by itself">
        </div>
    
    <div class="paragraph">
      
    <p>Artificial intelligence (AI) is evolving—literally. Researchers have developed software that gets concepts from Darwinian evolution to build AI programs that improve generation after generation without human input, including "survival of the fittest." The program has replicated decades of AI research in a matter of days, and its designers believe that new approaches to AI could be discovered one day. While most people took baby steps, they made a giant leap into the unknown, "says Risto Miikkulainen, an informatics scientist at Texas University, Austin, who was not involved in the work. "Building an AI-algorithm takes time. Take the neural networks, a common type of machine learning used to translate language and drive automobiles. These networks loosely imitate the brain structure, and learn from training data by altering the strength of artificial neuronal connections. Smaller neuronal subcircuits perform specific tasks — for example, spotting road signs — and researchers can spend months working out how to connect them so that they work seamlessly together. Scientists have sped up the process in recent years by automating a few steps. But those programs still rely on human-designed ready-made circuits being stitched together. That means that the output is still limited by the imaginations of the engineers and their existing biases. So Quoc Le, a Google computer scientist, and colleagues developed a program called AutoML-Zero that could effectively develop AI programs with zero human input, using only the basic mathematical concepts a high school student would know about. "Our ultimate goal is to actually develop novel machine learning concepts that could not even be found by researchers," he says. The program uses loose approximation of evolution to discover algorithms. It begins by creating a population of 100 candidate algorithms, by combining mathematical operations randomly. It then tests them on a simple task, such as a problem of image recognition where it has to decide whether a picture displays a cat or a truck. The program compares performance of the algorithms against hand-designed algorithms in each cycle. Copies of the top performers are "mutated" to create slight variations of the best algorithms by randomly replacing, editing, or deleting some of its code. These "children" are added to the population whilst older programs are being taught. The cycle is repeating itself. The system creates thousands of those populations at once, allowing it to churn through tens of thousands of algorithms a second until a good solution is found. The program also uses techniques to speed up the search, such as occasionally exchanging algorithms between populations to avoid any evolutionary dead ends, and automatically weeding out duplicate algorithms. In a preprint paper published on arXiv last month, the researchers demonstrate that the approach can stumble on a number of classic machine learning methods including neural networks. Compared to the most advanced algorithms of today, the solutions are simple, Le admits, but he says the work is a proof of principle and he's optimistic it can be scaled up to create much more complex Als Still, Joaquin Vanschoren, an informatics scientist at Eindhoven University of Technology, thinks it'll be a while before the approach can compete with the state of the art. One thing that could improve the programme, he says, is not to ask it to start from scratch, but to seed it with some of the tricks and techniques that humans have discovered. "We can prime the pump with learned machine learning concepts." That is something Le plans to work on. He adds that focussing on smaller issues rather than whole algorithms also holds promise. On 6 April his group published another paper on arXiv, using a similar approach to redesigning a popular ready-made component used in many neural networks. But Le also believes that boosting the library's number of mathematical operations and devoting even more computing resources to the program could allow it to discover completely new AI capabilities. "That is a truly passionate direction," he says. "To discover something really fundamental that will take human beings a long time to figure out."
</p>
   </div>
    
     <div class="header2">
      <h1>The beginning of AI:</h1>
     </div>
   <div class="img">  <img src="pics/Alan Mathison Turing.jpg" alt=" Alan Mathison Turing">
   </div>
<div class="paragraph">
      
<p>Artificial Intelligence (AI), the ability of a computer-controlled robot or digital computer to perform tasks common to smart beings. The term is often applied to the project of developing systems equipped with human-characteristic intellectual processes such as the ability to reason , discover meaning, generalize or learn from past experience. The conception of Turing is now simply known as the universal Turing machine. In essence, all the modern computers are universal Turing machines. During World War II Turing was a leading cryptanalyst in Bletchley Park, Buckinghamshire, England at the Government Code and Cypher School. Till the cessation of hostilities in Europe in 1945 Turing could not turn to the project of building a stored-program electronic computing machine. Nevertheless, he had given considerable thought to the question of machine intelligence during the war. One of Turing 's colleagues at Bletchley Park, Donald Michie (who later founded University of Edinburgh's Department of Machine Intelligence and Perception), Later, it was recalled that Turing frequently discussed how computers could learn from experience and solve new problems by using guiding principles — a process now known as heuristic problem solving. Turing quite possibly gave the earliest public lecture (London, 1947) to mention computer intelligence, saying, "What we want is a machine that can learn from experience," And that "the possibility of letting the machine change its own instructions provides the mechanism for that." In 1948, in a report entitled "Intelligent Machinery," Turing introduced many of the central concepts of AI. However, this paper was not published, and many of his ideas were later reinvented by others. For example, one of Turing's original ideas was to train an artificial neuron network to perform specific tasks, an approach that was described in the section on Connectionism.</p>
   </div>

<br>

 <div class="header2">
      <h1>The first AI programs</h1>
     </div>

<div class="paragraph">
    <p>Christopher Strachey, later director of Programing Research Group at the University of Oxford, wrote the earliest successful AI program in 1951. Strachey's checkers (draughts) program run at the University of Manchester, England, on the Ferranti Mark I computer. This program could play a complete game of checkers at a reasonable speed by the summer of 1952. Information regarding the earliest successful machine learning demonstration was published in 1952. Shopper, written by University of Cambridge's Anthony Oettinger, ran on the EDSAC computer. The simulated world of shopper was a mall comprising eight shops. Shopper would search for it when instructed to buy an item, visiting shops at random until the item is found. Shopper would memorize a few of the items stored in each visited shop while searching (just as a human shopper might do). The next time Shopper was sent out for the same item, or it would go straight to the right store for some other item that it had already located. This simple form of learning, as the introductory section on What is Intelligence points out? The rote learning is called. The first AI program to run in the United States was also a checkers program, written for the IBM 701 prototype by Arthur Samuel in 1952. Samuel took over the essentials of Strachey's checkers program and considerably extended it over a period of years. He added features in 1955 which allowed the program to learn from experience. Samuel included mechanisms for both rotary learning and generalization, improvements that eventually led to winning one game against a former Connecticut checkers champion in 1962 for his program.</p>
   </div>
<div class="header2">
      <h1>Evolutionary computing</h1>
     </div>

 <div class="img">
  <img src="pics/Evolutionary computing.jpg" alt="Evolutionary computing">
 </div>
<div class="paragraph">
<p>It was also notable that Samuel's checkers program was one of the first efforts at evolutionary computing. (His program "evolved" by pitting a modified copy against the current best version of his program, with the winner becoming the new standard.) Evolutionary computing typically involves the use of some automatic methods to generate and evaluate successive program "generations" until a highly skilled solution develops. John Holland, a leading proponent of evolutionary computing, wrote test software for the IBM 701 computer prototype, too. In particular, he helped design a "virtual" rat, a neural network that could be trained to navigate through a labyrinth. This work convinced Holland of the efficacy of the bottom-up approach. In 1952 Holland moved to the University of Michigan to pursue a doctorate in mathematics while continuing to consult for IBM. However, he soon switched to a new interdisciplinary computer and information processing program (later known as communications science), created by Arthur Burks, one of ENIAC's builders and its successor EDVAC. Holland proposed a new type of computer — a multiprocessor computer — that would assign each artificial neuron in a network to a separate processor in his 1959 dissertation, most likely the world's first computer science Ph D. (In 1985 Daniel Hillis resolved the engineering difficulties of building the first such computer, the 65,536-processor Thinking Machines Corporation supercomputer.) After graduation, Holland joined the faculty in Michigan, and over the next four decades he directed much research into methods of automating evolutionary computing, a process now known as genetic algorithms. Holland's laboratory implemented systems included a chess program, single-cell biological organism models, and a classifier system for controlling a simulated gas-pipeline network. However, genetic algorithms are no longer restricted to "academic" demonstrations; a genetic algorithm cooperates with a witness to a crime to generate a portrait of the criminal in one important practical application.</p>
   </div>

<div class="header2">
      <h1>Logical reasoning and problem solving</h1>
     </div>

<div class="img"> <img src="pics/proplems in AI.jpg" alt="proplems in AI">
</div>
<div class="paragraph">
<p>An important aspect of intelligence is the ability to reason logically and has always been a major focus of AI research. A significant landmark in this area was a theorem-proving program written by Allen Newell and J in 1955–56. RAND Corporation's Clifford Shaw, and Carnegie Mellon University's Herbert Simon. As the program became known, the Logic Theorist was designed to prove theorems from Principia Mathematica (1910–13), a three-volume work by Alfred North Whitehead and Bertrand Russell, the British philosopher-mathematicians. A proof conceived by the program was in one instance more elegant than the proof given in the books. Newell, Simon and Shaw went on to write the General Problem Solver, or GPS, a more powerful programme. The first GPS version ran in 1957, and work on the project continued for about a decade. Using a trial and error approach GPS could solve an impressive variety of puzzles. One critique of GPS, however, and similar programs lacking any learning capability, is that the intelligence of the program is entirely second-hand, coming from whatever information the programmer explicitly includes.</p>
   </div>

<div class="header2">
      <h1>AI programming languages</h1>
     </div>

<div class="paragraph">
<p>Newell, Simon, and Shaw developed their Information Processing Language (IPL), a computer language tailored to AI programming, during their work on the Logic Theorist and GPS. At the heart of IPL was a highly flexible structure of data which they called a list. A list is merely a commanded sequence of data items. Some or all of the items in a list may be lists themselves. This scheme leads to structures which are richly branched.
In 1960, John McCarthy combined IPL elements with the lambda calculus (a formal mathematical-logical system) to produce the programming language LISP (List Processor), which remains the main language for AI work in the U.S. (The lambda calculus was invented by the Princeton logician Alonzo Church in 1936, while investigating the abstract decision-making problem, or "decision problem," for predicate logic — the same problem that Turing had faced when he invented the universal Turing machine.) The logic programming language PROLOG (Programmation en Logique) was designed by Alain Colmerauer at the Univiv. PROLOG was further developed by the University of Edinburgh logician Robert Kowalski, a member of the AI group. The ability to reason logically is an important aspect of intelligence, and has always been a major focus of AI research. A significant landmark in this area was a theorem-proving program drawn up in 1955–56 by Allen Newell and J. Clifford Shaw of RAND Corporation, and Herbert Simon of Carnegie Mellon University. As the program became known, the Logic Theorist was designed to prove theorems from Principia Mathematica (1910–13), a three-volume work by the British philosopher-mathematicians Alfred North Whitehead and Bertrand Russell. In one instance, a proof conceived by the programme was more elegant than the proof given in the books. Newell, Simon and Shaw went on to write a more powerful program called the General Problem Solver, or GPS. The first version of the GPS came out in 1957, and work on the project continued for about ten years. Using a trial and error approach GPS could solve a variety of impressive puzzles. However, one criticism of GPS, and similar programs lacking any learning capability, is that the program's intelligence is entirely second-hand, coming from whatever information the programmer explicitly includes.
</p>
   </div>

<div class="header2">
      <h1>Examples of AI technology</h1>
     </div>
<div class="paragraph">
<p>AI is incorporated into a variety of different types of technology. Here are six examples:</p>

        <ul style="line-height: 150%">
  <li>	<Span class="p2">Automation.</Span> When paired with AI technologies, automation tools can expand the volume and types of tasks performed. An example is robotic process automation (RPA), a type of software that automates repetitive, rules-based data processing tasks traditionally done by humans. When combined with machine learning and emerging AI tools, RPA can automate bigger portions of enterprise jobs, enabling RPA's tactical bots to pass along intelligence from AI and respond to process changes.</li>
  
  <li><Span class="p2">Machine learning.</Span> This is the science of getting a computer to act without programming. Deep learning is a subset of machine learning that, in very simple terms, can be thought of as the automation of predictive analytics. There are three types of machine learning algorithms:
                 <ol>
   <li><Span class="p3">Supervised learning.</Span> Data sets are labeled so that patterns can be detected and used to label new data sets.</li>
  <li>	<Span class="p3">Unsupervised learning.</Span> Data sets aren't labeled and are sorted according to similarities or differences.</li>
  <li>	<Span class="p3">Reinforcement learning.</Span> Data sets aren't labeled but, after performing an action or several actions, the AI system is given feedback. </li></li>
                 </ol>
                 
  <li><Span class="p2">Machine vision.</Span>	 This technology gives a machine the ability to see. Machine vision captures and analyzes visual information using a camera, analog-to-digital conversion and digital signal processing. It is often compared to human eyesight, but machine vision isn't bound by biology and can be programmed to see through walls, for example. It is used in a range of applications from signature identification to medical image analysis. Computer vision, which is focused on machine-based image processing, is often conflated with machine vision.</li>
  
  <li>	<Span class="p2">Natural language processing.</Span> This is the processing of human language by a computer program. One of the older and  best-known examples of NLP is spam detection, which looks at the subject line and text of an email and decides if it's junk. Current approaches to NLP are based on machine learning. NLP tasks include text translation, sentiment analysis and speech recognition.</li>
  
  <li><Span class="p2">Robotics.</Span> This field of engineering focuses on the design and manufacturing of robots. Robots are often used to perform tasks that are difficult for humans to perform or perform consistently. For example, robots are used in assembly lines for car production or by NASA to move large objects in space. Researchers are also using machine learning to build robots that can interact in social settings </li>
  
  <li>	<Span class="p2">Self-driving cars.</Span> Autonomous vehicles use a combination of computer vision, image recognition and deep learning to build automated skill at piloting a vehicle while staying in a given lane and avoiding unexpected obstructions, such as pedestrians. </li>
          </ul>
   </div>
<div class="header2">
      <h1>Narrow Artificial Intelligence</h1>
     </div>

<div class="paragraph">
<p>Narrow AI is all around us, and is the most successful artificial intelligence realization to date. With its focus on performing specific tasks, Narrow AI has experienced numerous breakthroughs over the last decade that have had "significant societal benefits and contributed to the nation's economic vitality," according to the Obama administration's 2016 report "Preparing for the Future of Artificial Intelligence."</p>
<P>examples of Narrow AI include: </P>
<ul>
  <li>Google search</li>
  <li>Image recognition software</li>
  <li>Siri, Alexa and other personal assistants</li>
  <li>Self-driving cars</li>
  <li>IBM's Watson </li>
</ul>
   </div>
    </body>
</html>